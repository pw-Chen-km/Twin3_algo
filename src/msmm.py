"""
MSMM (Multi-Semantic Matching Module)
è² è²¬å°‡ç”¨æˆ¶å…§å®¹æ˜ å°„åˆ°æœ€ç›¸é—œçš„ç¶­åº¦
"""

import json
import re
import os
from typing import List, Dict, Tuple
from sentence_transformers import SentenceTransformer
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

# Gemma-3 å¤šæ¨¡æ…‹ LLM æ•´åˆ
try:
    from transformers import AutoProcessor, AutoModelForImageTextToText
    import torch
    GEMMA_AVAILABLE = True
except ImportError:
    print("è­¦å‘Šï¼štransformersæœªå®‰è£ï¼Œå°‡ä½¿ç”¨æ¨¡æ“¬æ¨¡å¼")
    GEMMA_AVAILABLE = False

class MSMMProcessor:
    def __init__(self, 
                 metadata_path: str = "../metadata/attribute_metadata.json",
                 gemma_model_name: str = "google/gemma-3n-E4B-it",  # å‡ç´šåˆ°Gemma-3n-E4B
                 local_model_path: str = None,  # é»˜èªå¾HFä¸‹è¼‰
                 use_local_gemma: bool = True):
        """åˆå§‹åŒ–MSMMè™•ç†å™¨"""
        self.metadata_path = metadata_path
        self.metadata = self._load_metadata()
        self.use_local_gemma = use_local_gemma and GEMMA_AVAILABLE
        self.local_model_path = local_model_path
        
        # åˆå§‹åŒ–Sentence-BERTæ¨¡å‹ï¼ˆä½¿ç”¨å¤šèªè¨€æ¨¡å‹ï¼‰
        try:
            self.sentence_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        except:
            print("è­¦å‘Šï¼šç„¡æ³•è¼‰å…¥å¤šèªè¨€æ¨¡å‹ï¼Œä½¿ç”¨åŸºç¤è‹±æ–‡æ¨¡å‹")
            self.sentence_model = SentenceTransformer('all-MiniLM-L6-v2')
        
        # åˆå§‹åŒ–Gemmaæ¨¡å‹
        if self.use_local_gemma:
            self._initialize_gemma(gemma_model_name, local_model_path)
        else:
            print("è­¦å‘Šï¼šä½¿ç”¨è¦å‰‡å¼•æ“æ¨¡æ“¬Meta-Tagæå–")
        
        # é å…ˆè¨ˆç®—æ‰€æœ‰ç¶­åº¦çš„å‘é‡è¡¨ç¤º
        self._precompute_attribute_vectors()
    
    def _initialize_gemma(self, model_name: str, local_path: str = None):
        """åˆå§‹åŒ–Gemmaæ¨¡å‹ï¼ˆå„ªå…ˆä½¿ç”¨æœ¬åœ°è·¯å¾‘ï¼‰"""
        try:
            # å„ªå…ˆä½¿ç”¨æœ¬åœ°è·¯å¾‘ï¼Œå¦‚æœä¸å­˜åœ¨å‰‡å ±éŒ¯è€Œä¸æ˜¯å›åˆ°ç·šä¸Š
            if local_path and os.path.exists(local_path):
                model_path = local_path
                print(f"æ­£åœ¨è¼‰å…¥æœ¬åœ°Gemmaæ¨¡å‹: {model_path}")
                print("ä½¿ç”¨æœ¬åœ°æ¨¡å‹")
            elif local_path:
                print(f"âŒ æ‰¾ä¸åˆ°æœ¬åœ°æ¨¡å‹: {local_path}")
                print("è«‹ç¢ºèªæ¨¡å‹å·²ä¸‹è¼‰åˆ°æ­£ç¢ºä½ç½®ï¼Œæˆ–ä½¿ç”¨ --no-gemma æ¨¡å¼")
                raise FileNotFoundError(f"æœ¬åœ°æ¨¡å‹ä¸å­˜åœ¨: {local_path}")
            else:
                # å¦‚æœæ²’æœ‰æŒ‡å®šæœ¬åœ°è·¯å¾‘ï¼Œä½¿ç”¨ç·šä¸Šæ¨¡å‹
                model_path = model_name
                print(f"æ­£åœ¨è¼‰å…¥ç·šä¸ŠGemmaæ¨¡å‹: {model_path}")
                print("ğŸŒ ä½¿ç”¨åœ¨ç·šæ¨¡å‹")
            
            # ä½¿ç”¨Gemma-3çš„Processorï¼ˆæ”¯æŒå¤šæ¨¡æ…‹ï¼‰
            self.gemma_processor = AutoProcessor.from_pretrained(model_path)
            
            # æª¢æŸ¥å¯ç”¨çš„è¨­å‚™
            if torch.backends.mps.is_available():
                device = "mps"
                dtype = torch.float16
                print("ğŸš€ æª¢æ¸¬åˆ° Apple Siliconï¼Œä½¿ç”¨ MPS åŠ é€Ÿ")
            elif torch.cuda.is_available():
                device = "cuda"
                dtype = torch.float16
                print("ğŸš€ æª¢æ¸¬åˆ° CUDAï¼Œä½¿ç”¨ GPU åŠ é€Ÿ")
            else:
                device = "cpu"
                dtype = torch.float32
                print("ğŸ’» ä½¿ç”¨ CPU é‹ç®—")
            
            # ä½¿ç”¨Gemma-3çš„å¤šæ¨¡æ…‹æ¨¡å‹
            self.gemma_model = AutoModelForImageTextToText.from_pretrained(
                model_path,
                torch_dtype=dtype,
                low_cpu_mem_usage=True
            )
            
            # æ‰‹å‹•ç§»å‹•æ¨¡å‹åˆ°ç›®æ¨™è¨­å‚™ï¼ŒåŒ…å«éŒ¯èª¤è™•ç†
            try:
                self.gemma_model = self.gemma_model.to(device)
                self.device = device
                print(f"âœ… Gemma-3æ¨¡å‹å·²ç§»å‹•åˆ° {device} è¨­å‚™")
            except Exception as device_error:
                print(f"âš ï¸ ç„¡æ³•ç§»å‹•åˆ° {device} è¨­å‚™: {device_error}")
                print("ğŸ’» å›é€€è‡³ CPU é‹ç®—")
                self.device = "cpu"
                self.gemma_model = self.gemma_model.to("cpu")
            
            print(f"âœ… Gemma-3å¤šæ¨¡æ…‹æ¨¡å‹è¼‰å…¥æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ Gemma-3æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
            print("å°‡å›é€€è‡³è¦å‰‡å¼•æ“æ¨¡å¼")
            self.use_local_gemma = False
    
    def _load_metadata(self) -> Dict:
        """è¼‰å…¥ç¶­åº¦å…ƒæ•¸æ“š"""
        try:
            with open(self.metadata_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            print(f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°å…ƒæ•¸æ“šæ–‡ä»¶ {self.metadata_path}")
            return {}
    
    def _precompute_attribute_vectors(self):
        """é å…ˆè¨ˆç®—æ‰€æœ‰ç¶­åº¦çš„å‘é‡è¡¨ç¤º"""
        self.attribute_vectors = {}
        
        for attr_id, attr_data in self.metadata.items():
            # å°‡Meta-Tagsçµ„åˆæˆæ–‡æœ¬
            meta_tags_text = " ".join(attr_data["attribute_meta_tags"])
            
            # è¨ˆç®—å‘é‡
            vector = self.sentence_model.encode([meta_tags_text])
            self.attribute_vectors[attr_id] = vector[0]
            
        print(f"å·²é è¨ˆç®— {len(self.attribute_vectors)} å€‹ç¶­åº¦çš„å‘é‡è¡¨ç¤º")
    
    def _construct_meta_tag_extraction_messages(self, user_content: str, image_url: str = None) -> List[Dict]:
        """å»ºæ§‹Meta-Tagæå–çš„Gemma-3 messagesï¼ˆæ”¯æŒå¤šæ¨¡æ…‹ï¼‰"""
        
        # æ”¶é›†æ‰€æœ‰ç¾æœ‰çš„Meta-Tagsä½œç‚ºåƒè€ƒ
        all_existing_tags = set()
        for attr_data in self.metadata.values():
            all_existing_tags.update(attr_data["attribute_meta_tags"])
        
        existing_tags_sample = list(all_existing_tags)[:30]  # å–æ¨£æœ¬é¿å…promptå¤ªé•·
        
        # æ§‹å»ºæ–‡æœ¬å…§å®¹
        text_content = f"""ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„å…§å®¹åˆ†æAIï¼Œéœ€è¦å¾ç”¨æˆ¶çš„ç”Ÿæ´»é«”é©—å…§å®¹ä¸­æå–é—œéµçš„Meta-Tagsã€‚

ä»»å‹™ï¼šåˆ†æä»¥ä¸‹ç”¨æˆ¶å…§å®¹ï¼Œæå–3-8å€‹æœ€èƒ½ä»£è¡¨å…¶æ ¸å¿ƒæ„ç¾©çš„Meta-Tagsã€‚

ç”¨æˆ¶å…§å®¹ï¼š"{user_content}"

æå–æŒ‡å°ï¼š
1. Meta-Tagsæ‡‰è©²æ˜¯ç°¡æ½”çš„ä¸­æ–‡è©å½™æˆ–è‹±æ–‡å–®è©
2. é‡é»é—œæ³¨è¡Œç‚ºã€æƒ…ç·’ã€å ´æ™¯ã€æŠ€èƒ½ã€åƒ¹å€¼è§€ç­‰æ ¸å¿ƒæ¦‚å¿µ
3. å¦‚æœæœ‰åœ–ç‰‡ï¼Œè«‹çµåˆåœ–ç‰‡å…§å®¹é€²è¡Œåˆ†æ
4. å¯åƒè€ƒä½†ä¸é™æ–¼ä»¥ä¸‹å·²çŸ¥æ¨™ç±¤ï¼š{', '.join(existing_tags_sample)}
5. é¿å…éæ–¼å…·é«”çš„åè©ï¼Œå‚¾å‘æ–¼å¯é‡è¤‡ä½¿ç”¨çš„æ¦‚å¿µæ¨™ç±¤

è«‹åƒ…è¿”å›Meta-Tagsåˆ—è¡¨ï¼Œç”¨é€—è™Ÿåˆ†éš”ï¼Œä¸è¦å…¶ä»–èªªæ˜æ–‡å­—ã€‚

ä¾‹å¦‚ï¼šå­¸ç¿’, æˆå°±æ„Ÿ, åœ˜éšŠåˆä½œ, é£Ÿç‰©, æ…¶ç¥"""
        
        # æ§‹å»ºæ¶ˆæ¯å…§å®¹
        content = []
        
        # å¦‚æœæœ‰åœ–ç‰‡ï¼Œå…ˆæ·»åŠ åœ–ç‰‡
        if image_url:
            content.append({"type": "image", "url": image_url})
        
        # æ·»åŠ æ–‡æœ¬
        content.append({"type": "text", "text": text_content})
        
        messages = [
            {
                "role": "user",
                "content": content
            }
        ]
        
        return messages
    
    def _call_gemma_for_meta_tags(self, user_content: str, image_url: str = None) -> List[str]:
        """ä½¿ç”¨Gemma-3å¤šæ¨¡æ…‹æ¨¡å‹æå–å…§å®¹Meta-Tags"""
        try:
            # 1. æ§‹å»ºå¤šæ¨¡æ…‹æ¶ˆæ¯æ ¼å¼
            messages = self._construct_meta_tag_extraction_messages(user_content, image_url)

            # 2. ä½¿ç”¨Processorè™•ç†å¤šæ¨¡æ…‹è¼¸å…¥
            inputs = self.gemma_processor.apply_chat_template(
                messages,
                add_generation_prompt=True,
                tokenize=True,
                return_dict=True,
                return_tensors="pt"
            ).to(self.device)

            # 3. ç”Ÿæˆå›æ‡‰
            with torch.no_grad():
                outputs = self.gemma_model.generate(
                    **inputs,
                    max_new_tokens=50,
                    temperature=0.3,
                    do_sample=True
                )

            # 4. è§£ç¢¼æ–°å…§å®¹
            response = self.gemma_processor.decode(
                outputs[0][inputs["input_ids"].shape[-1]:],
                skip_special_tokens=True
            ).strip()

            print(f"Gemma-3åŸå§‹å›æ‡‰: {response}")
            if image_url:
                print(f"  (åŒ…å«åœ–ç‰‡åˆ†æ: {image_url[:50]}...)")

            # 5. è§£æMeta-Tags
            if ',' in response:
                meta_tags = [tag.strip() for tag in response.split(',')]
            else:
                meta_tags = [tag.strip() for tag in re.split(r'[ã€\s]+', response)]
            meta_tags = [tag for tag in meta_tags if tag and len(tag) > 1 and len(tag) < 20]
            return meta_tags[:8]
        except Exception as e:
            print(f"Gemma-3èª¿ç”¨éŒ¯èª¤: {e}")
            return self._fallback_meta_tag_extraction(user_content)
    
    def _fallback_meta_tag_extraction(self, user_content: str) -> List[str]:
        """å›é€€çš„è¦å‰‡å¼•æ“Meta-Tagæå–"""
        content_lower = user_content.lower()
        
        # å®šç¾©é—œéµè©æ˜ å°„
        keyword_mappings = {
            "achievement": ["å®Œæˆ", "æˆå°±", "æˆåŠŸ", "é”æˆ", "ç²å¾—", "è´å¾—", "å¯¦ç¾"],
            "leadership": ["å¸¶é ˜", "é ˜å°", "æŒ‡å°", "ç®¡ç†", "ä¸»æŒ", "çµ±ç±Œ", "å”èª¿"],
            "food": ["åƒ", "é£Ÿç‰©", "é¤å»³", "æ–™ç†", "æ—©é¤", "åˆé¤", "æ™šé¤", "ç«é‹", "å°åƒ"],
            "learning": ["å­¸ç¿’", "ç ”ç©¶", "é–±è®€", "èª²ç¨‹", "æŠ€å·§", "çŸ¥è­˜", "æ›¸"],
            "creative": ["å‰µä½œ", "è¨­è¨ˆ", "è—è¡“", "éŸ³æ¨‚", "ç•«ä½œ", "æ”å½±"],
            "exercise": ["é‹å‹•", "å¥èº«", "è·‘æ­¥", "æ¸¸æ³³", "ç‘œä¼½", "è¨“ç·´"],
            "social": ["æœ‹å‹", "èšæœƒ", "ç¤¾äº¤", "åœ˜é«”", "ç¤¾å€", "å¿—å·¥", "æ…ˆå–„"],
            "technology": ["ç¨‹å¼", "ç§‘æŠ€", "è»Ÿé«”", "é›»è…¦", "AI", "æ•¸ä½"],
            "environment": ["æ°¸çºŒ", "ç’°ä¿", "æ¸›ç¢³", "ç¶ è‰²", "ç”Ÿæ…‹", "æ°£å€™", "åƒåœ¾åˆ†é¡", "æœ‰æ©Ÿ", "å†ç”Ÿèƒ½æº"]
        }
        
        extracted_tags = []
        
        for tag, keywords in keyword_mappings.items():
            for keyword in keywords:
                if keyword in content_lower:
                    extracted_tags.append(tag)
                    break
        
        # å¦‚æœæ²’æœ‰æå–åˆ°æ¨™ç±¤ï¼Œè¿”å›åŸå§‹å…§å®¹çš„é‡è¦è©å½™
        if not extracted_tags:
            words = re.findall(r'[\u4e00-\u9fff]+|[a-zA-Z]+', user_content)
            extracted_tags = [word for word in words if len(word) > 1][:5]
        
        return list(set(extracted_tags))  # å»é‡
    
    def extract_content_meta_tags(self, user_content: str, image_url: str = None) -> List[str]:
        """
        æå–å…§å®¹Meta-Tagsï¼ˆæ”¯æŒå¤šæ¨¡æ…‹ï¼‰
        å„ªå…ˆä½¿ç”¨Gemma-3ï¼Œå¤±æ•—æ™‚å›é€€è‡³è¦å‰‡å¼•æ“
        """
        if self.use_local_gemma:
            try:
                return self._call_gemma_for_meta_tags(user_content, image_url)
            except Exception as e:
                print(f"Gemma-3æå–å¤±æ•—ï¼Œä½¿ç”¨è¦å‰‡å¼•æ“: {e}")
                return self._fallback_meta_tag_extraction(user_content)
        else:
            return self._fallback_meta_tag_extraction(user_content)
    
    def extract_meta_tags(self, user_content: str, image_url: str = None) -> List[str]:
        """
        æå–Meta-Tagsçš„çµ±ä¸€æ¥å£ï¼ˆæ”¯æŒå¤šæ¨¡æ…‹ï¼‰
        """
        return self.extract_content_meta_tags(user_content, image_url)
    
    def find_matching_attributes(self, user_content: str, image_url: str = None, top_n: int = 5) -> List[Tuple[str, float, str]]:
        """
        æ‰¾åˆ°æœ€åŒ¹é…çš„ç¶­åº¦ï¼ˆæ”¯æŒå¤šæ¨¡æ…‹ï¼‰
        ä½¿ç”¨å–®å€‹meta-tagèˆ‡å–®å€‹attribute meta-tagçš„æ‰¹æ¬¡æ¯”å°
        è¿”å›ï¼š[(attribute_id, similarity_score, attribute_name), ...]
        """
        # æå–å…§å®¹Meta-Tagsï¼ˆæ”¯æŒåœ–ç‰‡ï¼‰
        content_meta_tags = self.extract_content_meta_tags(user_content, image_url)
        
        print(f"æå–åˆ°çš„å…§å®¹Meta-Tags: {content_meta_tags}")
        
        if not content_meta_tags:
            return []
        
        # æº–å‚™æ‰€æœ‰éœ€è¦æ¯”å°çš„é…å°
        user_tags_for_batch = []
        attr_tags_for_batch = []
        attr_mapping = []  # è¨˜éŒ„æ¯å€‹é…å°å±¬æ–¼å“ªå€‹ç¶­åº¦
        
        for user_tag in content_meta_tags:
            for attr_id, attr_data in self.metadata.items():
                for attr_tag in attr_data["attribute_meta_tags"]:
                    user_tags_for_batch.append(user_tag)
                    attr_tags_for_batch.append(attr_tag)
                    attr_mapping.append(attr_id)
        
        print(f"æº–å‚™é€²è¡Œ {len(user_tags_for_batch)} å€‹é…å°çš„batchæ¯”å°")
        
        # æ‰¹æ¬¡è¨ˆç®—å‘é‡
        if user_tags_for_batch and attr_tags_for_batch:
            user_vectors = self.sentence_model.encode(user_tags_for_batch)
            attr_vectors = self.sentence_model.encode(attr_tags_for_batch)
            
            # è¨ˆç®—ç›¸ä¼¼åº¦
            similarities_batch = cosine_similarity(user_vectors, attr_vectors)
            
            # æå–å°è§’ç·šï¼ˆæ¯å€‹é…å°çš„ç›¸ä¼¼åº¦ï¼‰
            pair_similarities = similarities_batch.diagonal()
        else:
            pair_similarities = []
        
        # èšåˆæ¯å€‹ç¶­åº¦çš„å¾—åˆ†
        attr_scores = {}
        attr_details = {}  # è¨˜éŒ„æ¯å€‹ç¶­åº¦çš„è©³ç´°åŒ¹é…æƒ…æ³
        
        for i, (user_tag, attr_tag, attr_id, similarity) in enumerate(zip(
            user_tags_for_batch, attr_tags_for_batch, attr_mapping, pair_similarities
        )):
            if attr_id not in attr_scores:
                attr_scores[attr_id] = 0
                attr_details[attr_id] = []
            
            # ç´¯åŠ ç›¸ä¼¼åº¦åˆ†æ•¸
            attr_scores[attr_id] += similarity
            
            # è¨˜éŒ„é«˜ç›¸ä¼¼åº¦çš„é…å°ï¼ˆç”¨æ–¼debugï¼‰
            if similarity > 0.8:
                attr_details[attr_id].append(f"{user_tag}â†”{attr_tag}({similarity:.3f})")
        
        # è¨ˆç®—å¹³å‡åˆ†æ•¸ï¼ˆé¿å…ç¶­åº¦meta-tagæ•¸é‡å¤šçš„ä½”å„ªå‹¢ï¼‰
        for attr_id in attr_scores:
            num_attr_tags = len(self.metadata[attr_id]["attribute_meta_tags"])
            num_user_tags = len(content_meta_tags)
            # å¹³å‡åˆ†æ•¸ = ç¸½åˆ†æ•¸ / (ç¶­åº¦æ¨™ç±¤æ•¸ * ç”¨æˆ¶æ¨™ç±¤æ•¸)
            attr_scores[attr_id] = attr_scores[attr_id] / (num_attr_tags * num_user_tags)
        
        # é¡¯ç¤ºè©³ç´°åŒ¹é…æƒ…æ³
        print(f"\né«˜ç›¸ä¼¼åº¦é…å°è©³æƒ…ï¼ˆ>0.8ï¼‰ï¼š")
        for attr_id, details in attr_details.items():
            if details:
                attr_name = self.metadata[attr_id]["attribute_name"]
                print(f"  {attr_id}-{attr_name}: {', '.join(details)}")
        
        # æ’åºä¸¦è¿”å›å‰Nå€‹
        similarities = [
            (attr_id, score, self.metadata[attr_id]["attribute_name"])
            for attr_id, score in attr_scores.items()
        ]
        similarities.sort(key=lambda x: x[1], reverse=True)
        
        return similarities[:top_n]
    
    def process_user_content(self, user_content: str, image_url: str = None, threshold: float = 0.1) -> List[Dict]:
        """
        è™•ç†ç”¨æˆ¶å…§å®¹ï¼Œè¿”å›åŒ¹é…çš„ç¶­åº¦ä¿¡æ¯ï¼ˆæ”¯æŒå¤šæ¨¡æ…‹ï¼‰
        """
        print(f"\n=== MSMM èªæ„åŒ¹é…åˆ†æ ===")
        print(f"ç”¨æˆ¶å…§å®¹: {user_content}")
        if image_url:
            print(f"åŒ…å«åœ–ç‰‡: {image_url}")
        print(f"ç›¸ä¼¼åº¦é–¾å€¼: {threshold}")
        
        matching_attributes = self.find_matching_attributes(user_content, image_url)
        
        # éæ¿¾ä½æ–¼é–¾å€¼çš„çµæœ
        filtered_results = [
            {
                "attribute_id": attr_id,
                "attribute_name": attr_name,
                "similarity_score": score
            }
            for attr_id, score, attr_name in matching_attributes
            if score >= threshold
        ]
        
        print(f"\nåŒ¹é…åˆ°çš„ç¶­åº¦ (ç›¸ä¼¼åº¦ >= {threshold}):")
        for result in filtered_results:
            print(f"  {result['attribute_id']}-{result['attribute_name']}: {result['similarity_score']:.3f}")
        
        if not filtered_results:
            print("  æ²’æœ‰æ‰¾åˆ°ç¬¦åˆé–¾å€¼çš„åŒ¹é…ç¶­åº¦")
        
        return filtered_results

# æ¸¬è©¦å‡½æ•¸
def test_msmm():
    """æ¸¬è©¦MSMMæ¨¡çµ„"""
    msmm = MSMMProcessor()
    
    test_content = "æˆ‘ä»Šå¤©å¸¶é ˜å­¸å¼Ÿå¦¹å®Œæˆäº†ä¸€ç¯‡è«–æ–‡ï¼Œé‚„é †ä¾¿å»åƒäº†æœ‰åçš„å°å¼æ—©é¤æ…¶ç¥ã€‚"
    results = msmm.process_user_content(test_content)
    
    return results

if __name__ == "__main__":
    test_msmm() 